---
title: "Beers Team Project"
author: "Celia"
date: "10/25/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set( echo = TRUE, message=FALSE, warning=FALSE, fig.width=8 )
```
# Establish Libraries
```{r}
library(ggplot2)
library(plotly)
library(lattice)
library(tidyverse)
library(class)
library(caret)
library(e1071)
library(xlsx)
library(stats)
```
## Code from week2 since EDA will be presented
### Libraries for visualization techniques are needed
```{r}
library(MASS)
library(dplyr)
library(readr)
library(GGally)
library(plotly)
library(ggthemes)
library(geofacet) #for geographic-based facets
library(naniar) #help with missing values
library(leaflet) #for map visualization
```
## Prepare data
```{r}
### read in dataset
### added Type column to create beer types as factors later on
beer <- read.xlsx(file="Beers_NEW.xlsx", sheetIndex = 1,   header=TRUE, stringsAsFactors = FALSE)

### Added state Latitude, Longitude, and Region columns in Excel
brewery <- read.xlsx(file="Breweries.xlsx", sheetIndex = 1,   header=TRUE, stringsAsFactors = FALSE)

## View(beer)
head(beer, 10)

## identify column names
names(beer)
names(brewery)
```
# VISUALIZATIONS

## Begin prepare an interactive geo map of breweries by state
```{r}
## Set the map useing leaflet library:
#leaflet()%>%addTiles()

leaflet()%>%addTiles(urlTemplate = "http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png")

## Add popup for brewery information
brewery_map <- brewery%>%mutate(popup_info=paste(Name,"<br/>",City,"<br>",State,"<br>"))
## Check popup_info column of data added to dataset
head(brewery_map)
## Tweak the map with info layout, set circles smaller to enhance visual
#leaflet()%>%addTiles()
leaflet()%>%addTiles(urlTemplate = "http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png")%>%addCircleMarkers(data=brewery_map, lat=~Latitude, lng=~Longitude, radius=~1, popup=~popup_info)
# End prepare an interactive geo map of breweries by state#

# Corresponding distribution plot of breweries by state
ggplot(brewery_map, aes(x=as.factor(State), color="blue")) +
  geom_bar(color="blue") +
  ggtitle("Distribution of Breweries by State") +
  xlab("State") +
  geom_text(stat='count', aes(label=after_stat(count)), vjust=-.25) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90))+
  theme(plot.title = element_text(hjust = 0.5))

# Corresponding distribution plot of breweries by region
ggplot(brewery_map, aes(x=as.factor(Region), color="green")) +
  geom_bar(color="green") +
  ggtitle("Distribution of Breweries by Region") +
  xlab("Region") +
  geom_text(stat='count', aes(label=after_stat(count)), vjust=-.25) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90)) +
  theme(plot.title = element_text(hjust = 0.5))
```
# Begin-Exploratory Data Analysis #
```{r}
## Examine the datasets
head(beer, 5)
head(brewery, 5)

## Merge the datasets
merge_bb <- merge(beer, brewery, by.x="Brewery_id", by.y="Brew_ID")

head(merge_bb, 5)

## Drop latitude and longitude columns as no longer needed
drop <- c("Latitude","Longitude")
df = merge_bb[,!(names(merge_bb) %in% drop)]

names(df)
## Rename columns to avoid confusion
df <- df %>% 
  rename(
    Beer = Name.x,
    Brewery = Name.y
  )
str(df)

#Get count of breweries in each state
brewery_count <- aggregate(Brewery_id ~ State, df, sum) #gives column name for count as Brewery_ID

#Rename the Brewery_id column to Total_Breweries
brewery_count <- brewery_count %>%
   rename(
     Total_Breweries = Brewery_id 
)
```
## Check for missing values 
```{r}
library(naniar)
vis_miss(df)

#ABV, IBU and Style contain missing values - count
table(is.na(df$ABV))
table(is.na(df$IBU))
table(is.na(df$Type))
table(is.na(df$Style))

#view which beers do not have styles or types
df[is.na(df$Style),]
df[is.na(df$Type),]

#impute the rows with zeroes per Ryan
df$ABV[is.na(df$ABV)] <- 0
df$IBU[is.na(df$IBU)] <- 0

## How does this data relate to client Budweiser?
which(df$Brewery == "Budweiser") 
grep("Clydesdales^",df$Brewery)
```
```{r}
drop <- c("Region.y")
mergeABVIBU = merge_bb[,!(names(merge_bb) %in% drop)]

drop <- c("Region.y", "Style.y")
mergeABVIBU.Style = merge_bb[,!(names(merge_bb) %in% drop)]
```
# Visualize ABV v IBU medians by state and by region

```{r}
options(scipen = 999)
mergeABVIBU <- as.data.frame(mergeABVIBU)
mergeABVIBU.Style <- as.data.frame(mergeABVIBU.Style)
#by state
ggplot(mergeABVIBU, aes(ABV, IBU)) +
  geom_point() +
  ggtitle("Median ABV v IBU by State") +
  facet_wrap(vars(State)) 
#by region
ggplot(mergeABVIBU, aes(ABV, IBU, color=Region)) +
  geom_point() +
  ggtitle("Median ABV v IBU by Region") +
  facet_wrap(vars(Region)) 

#recheck for missing values
vis_miss(df)
```
# Summary Statistics
```{r}
#load the mosaic package/library
library(mosaic)
#load the psych package/library
library(psych)

#5-number summary
favstats(df$ABV)
favstats(df$IBU)

par(mfrow=c(2,2)) #resets graphics device
#histograms for ABV and IBU
hist(df$ABV, labels = TRUE)
hist(df$IBU, labels = TRUE)
```

```{r}
# Describe by Style or by Type
#describeBy(df, group=df$Style)
#describeBy(df,group=df$Type)
State_ABV <- aggregate(x = df$ABV,              
                       by = list(df$State),    
                       FUN = median)

State_IBU <- aggregate(x = df$IBU,              
                       by = list(df$State),    
                       FUN = median)
Style_ABV <- aggregate(x = df$ABV,              
          by = list(df$Style),    
         FUN = median)

Style_IBU <- aggregate(x = df$IBU,              
                       by = list(df$Style),    
                       FUN = median)
Type_ABV <- aggregate(x = df$ABV,              
                      by = list(df$Type),    
                      FUN = median)
Type_IBU <- aggregate(x = df$IBU,              
                      by = list(df$Type),    
                      FUN = median)
#correlation analysis
library(Hmisc)
cor(df$ABV, df$IBU)

#visualize correlations
library(GGally)
#Correlation plot of data
ggpairs(df, columns = 4:5, ggplot2::aes(colour=Type)) 

## Visualize summaries
#plot of ABV by Style
qplot(mergeABVIBU.Style$Style, mergeABVIBU.Style$ABV, color=mergeABVIBU.Style$Region) +
  ggtitle("Median ABV by Style") +
  xlab("Style") +
  ylab('ABV') + labs(color='Region')  +
  theme(legend.position="top",
        axis.text.x = element_text(angle = 90, size=6)) +
  theme(legend.text=element_text(size=6)) +
  theme(plot.title = element_text(hjust = 0.5, size=12))

#plot of IBU by Style
qplot(mergeABVIBU.Style$Style, mergeABVIBU.Style$IBU, color=mergeABVIBU.Style$Region) +
  ggtitle("Median IBU by Style") +
  xlab("Style") +
  ylab('IBU') + labs(color='Region') +
  theme(legend.position="top",
        axis.text.x = element_text(angle = 90, size=6)) +
  theme(legend.text=element_text(size=6)) +
  theme(plot.title = element_text(hjust = 0.5, size=12))

```
```{r}
dfALEIPA = df %>% filter(Type == "IPA" | Type == "ALE")
splitPerc = .70
trainIndices = sample(1:dim(dfALEIPA)[1],round(splitPerc * dim(dfALEIPA)[1]))
train = dfALEIPA[trainIndices,]
test = dfALEIPA[-trainIndices,]

## Get a visual of the relationship and see for nearest neighbor
par(mfrow=c(2,2)) #reset graphics device 
train %>% ggplot(aes(x=ABV, y=IBU, color=Type)) + geom_point() + ggtitle("kNN Classification Graphing ABV vs IBU by IPA and ALE Beer Types")
```
```{r}
## Separate visuals of ALE and IBU needed
### so to not misrepresent data

## Visual of train model for ALE
par(mfrow=c(2,2)) #reset graphics device 
plot_ALE = train %>% filter(Type == "ALE")
plot_ALE %>% ggplot(aes(x=ABV, y=IBU, color=Type)) + geom_point() + ggtitle("ABV vs IBU by ALE Beer Type")

## Visual of train model for IPA
par(mfrow=c(2,2)) #reset graphics device 
plot_IPA = train %>% filter(Type == "IPA")
plot_IPA %>% ggplot(aes(x=ABV, y=IBU, color=Type)) + geom_point() + ggtitle("ABV vs IBU by IPA Beer Type")
```
# kNN analysis 
## Conduct the k-NN
```{r}
#What does a confusion matrix tell you:
#"It is a summary of prediction results on a 
#classification problem. The number of correct and
#incorrect predictions are summarized with count values 
#and broken down by each class. This is the key to the 
#confusion matrix. The confusion matrix shows the ways 
#in which your classification model is confused when it 
#makes predictions. It gives you insight not only into 
#the errors being made by your classifier but more 
#importantly the types of errors that are being made.
#It is this breakdown that overcomes the limitation 
#of using classification accuracy alone."-machinelearningmastery.com

# Get the probabilities
# A confusion matrix is a summary of prediction results 
## on a classification problem.
## tes run at k=5
set.seed(2040) #for reproducibility
classifications = knn(train[,c(4,5)],test[,c(4,5)],train$Type, prob = TRUE, k = 5)
levels = rev(test$Type)
table(test$Type,classifications)
confusionMatrix(table(test$Type,classifications))
```
```{r}
#do for k=15
set.seed(2040) #for reproducibility
classifications = knn(train[,c(4,5)],test[,c(4,5)],train$Type, prob = TRUE, k = 15)
table(test$Type,classifications)
confusionMatrix(table(test$Type,classifications))
```
```{r}
head(dfALEIPA)
#check Type as factor
levels(dfALEIPA$Type)
```
## Do reverse levels for confusion matrix table:
```{r}
dfALEIPA$Type <- fct_rev(dfALEIPA$Type)
levels(dfALEIPA$Type)
```
# kNN analysis - continued
## re-run k=15 with Type reversed
```{r}
set.seed(2040) #for reproducibility
classifications = knn(train[,c(4,5)],test[,c(4,5)],train$Type, prob = TRUE, k = 15)
table(test$Type,classifications)
confusionMatrix(table(test$Type,classifications))
```
# Obtain optimal k value for the kNN model
```{r}
type_accuracy <- data.frame(accuract=numeric(75), k=numeric(75))
for (iter in 1:75) {
  type_class <- knn(train[,c(4,5)], test[c(4,5)],
                     train$Type,
                     prob=TRUE, k=iter)
  table(test$Type, type_class)
  cm <- confusionMatrix(table(test$Type, type_class))
  type_accuracy$accuracy[iter] <- cm$overall[1]
  type_accuracy$k[iter] <- iter
}

#plot of optimal k
par(mfrow=c(2,2)) #reset graphics device 
figure <- plot_ly(type_accuracy, x=type_accuracy$k, y=type_accuracy$accuracy, 
              type="scatter", mode="lines")
figure <- figure %>% layout(title='Optimal k for Model',
            xaxis = list(title = 'K value',
                          zeroline=TRUE),
            yaxis = list(title = 'Accuracy'))
figure

```
# Use Naive Bayes to compare against kNN...
```{r knitr, echo=FALSE}
library(knitr)
library(e1071)

#"A priori probability refers to the likelihood of an 
#event occurring when there is a finite amount of outcomes 
#and each is equally likely to occur. The outcomes in a 
#priori probability are not influenced by the prior outcome. 
#Or, put another way, any results to date will not give you an 
#edge in predicting future results." Investopedia 

#NB loop for average of many training/testing partition
iterations=100
masterAcc=matrix(nrow=iterations)
```
```{r}
#Naive Bayes - continued
dfALEIPA = df %>% filter(Type == "IPA" | Type == "ALE")
splitPerc = .70

for(j in 1:iterations)
{
  trainIndices = sample(1:dim(dfALEIPA)[1],round(splitPerc * dim(dfALEIPA)[1]))
  train = dfALEIPA[trainIndices,]
  test = dfALEIPA[-trainIndices,]

  model = naiveBayes(train[,c(4,5)],as.factor(train$Type),laplace=1)
  table(predict(model,test[,c(4,5)]),as.factor(test$Type))
  CM=confusionMatrix(table(predict(model,test[,c(4,5)]),as.factor(test$Type)))
  masterAcc[j]=CM$overall[1]  
}

MeanAcc=colMeans(masterAcc)
MeanAcc
```
```{r,echo = FALSE, warning = FALSE, message=FALSE, error=TRUE}
knitr::opts_chunk$set(cache=TRUE)
#plotting NaiveBayes
#requie naivebayes package
library(naivebayes)
# Fit the model with custom prior probabilities
nb <- naive_bayes(Type ~ ., data = dfALEIPA, prior = c(0.1, 0.3, 0.5), laplace=1)
# Visualize marginal distributions of two predictors
par(mfrow=c(2,2)) #reset graphics device 
plot(nb, which = c("ABV", "IBU"), ask = TRUE,
     arg.num = list(col = 1:3, lty = 1,
                    main = "Naive Bayes Plot", legend.position = "topright",
                    legend.cex = 0.55))

```
# How about a third test -- one that tests medians between ABV v IBU for IPAs and ABV v IBU for Ales?
## Try the wilcox ranked sum test for difference in medians
```{r}
#Type -> ABV | IBU| Diff ABV-IBU | Absolute Diff ABV-IBU | Rank

#test run of wilcox.test()
resABVIBU <- wilcox.test(dfALEIPA$ABV, dfALEIPA$IBU, exact=FALSE, mu=0, conf.int=T, 
                   conf.level=0.95, correct=F)
resABVIBU
```
```{r}
#for ABV
res <- wilcox.test(ABV ~ Type, data=dfALEIPA, exact=FALSE, mu=0, conf.int=T, 
                   conf.level=0.95, correct=F)
res
```
```{r}
#get p-value
res$p.value
#Reject the null - p-value (2.235033e-64)is significant (less than alpha of .05) 
#to suggest that we reject the null that median ABV for IPA and Ale
#is equal (actually, it is not equal)
```
```{r}
#for IBU
res2 <- wilcox.test(IBU ~ Type, data=dfALEIPA, exact=FALSE, mu=0, conf.int=T, 
                   conf.level=0.95, correct=F)
res2
```
```{r}
#get p-value
res2$p.value
#Reject the null - p-value (1.127045e-53) is significant (less than alpha of .05) 
#to suggest that we reject the null that median IBU for IPA and Ale
#is equal (actually, it is not equal)
```
```{r}
#correlation analysis
library(Hmisc)
cor(dfALEIPA$ABV, dfALEIPA$IBU)
```
# Visualize correlations

```{r}
library(GGally)
#Correlation plot of data
par(mfrow=c(2,2)) #reset graphics device 
ggpairs(dfALEIPA, columns = 4:5, ggplot2::aes(colour=Type)) +  ggtitle("Correlation Plot of ABV vs IBU by Beer Type") 
```
# Conclusion of Wilcoxon Rank Sum Test and overall problem analysis:
```{r}
#p-value is significant in rejecting the null hypothesis that ABV v IBU by
#the two beer types is equal.  
```